{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка и проверка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "jumoreski_posts = pd.read_csv('jumoreski.csv')\n",
    "jumoreski_posts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "itis_posts = pd.read_csv('itis_kfu.csv')\n",
    "itis_posts.head()\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Объединение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "jumoreski_posts['target'] = 'jumoreski'\n",
    "itis_posts['target'] = 'itis'\n",
    "posts = pd.concat([jumoreski_posts, itis_posts])\n",
    "posts = posts.reset_index(drop=True)\n",
    "posts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Удаление emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "regrex_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\"\n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "\n",
    "posts['text'] = posts['text'].apply(lambda x: regrex_pattern.sub(r'', x))\n",
    "posts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Удаление вспомогательных символов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "posts['text'] = posts['text'].apply(lambda x: x.replace('\\n', ' '))\n",
    "posts['text'] = posts['text'].apply(lambda x: x.replace('\\t', ' '))\n",
    "posts['text'] = posts['text'].apply(lambda x: x.replace('\\r', ' '))\n",
    "posts['text'] = posts['text'].apply(lambda x: x.replace('  ', ' '))\n",
    "posts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Удаление пунктуации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-12</td>\n",
       "      <td>ТЕЛЕГА удивительное рядом httpstmemyfavoriteju...</td>\n",
       "      <td>jumoreski</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-14</td>\n",
       "      <td>у неё представления о том как выглядят бипки</td>\n",
       "      <td>jumoreski</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-04-14</td>\n",
       "      <td>Может ли мyжчина забеpеменеть  Пока неизвестн...</td>\n",
       "      <td>jumoreski</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-14</td>\n",
       "      <td>Пришла повестка Армия не входит в планы 18 ап...</td>\n",
       "      <td>jumoreski</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-14</td>\n",
       "      <td>Два шотландца встречаются в середине Индийског...</td>\n",
       "      <td>jumoreski</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                               text     target\n",
       "0  2023-04-12  ТЕЛЕГА удивительное рядом httpstmemyfavoriteju...  jumoreski\n",
       "1  2023-04-14       у неё представления о том как выглядят бипки  jumoreski\n",
       "2  2023-04-14   Может ли мyжчина забеpеменеть  Пока неизвестн...  jumoreski\n",
       "3  2023-04-14   Пришла повестка Армия не входит в планы 18 ап...  jumoreski\n",
       "4  2023-04-14  Два шотландца встречаются в середине Индийског...  jumoreski"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "posts['text'] = posts['text'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
    "posts['text'] = posts['text'].apply(lambda x: x.translate(str.maketrans('', '', '«»-—')))\n",
    "posts['text'] = posts['text'].apply(lambda x: x.replace('  ', ' '))\n",
    "posts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Приведение к нижнему регистру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "posts['text'] = posts['text'].apply(lambda x: x.lower())\n",
    "posts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Токенизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "corpus = {}\n",
    "for i in range(len(posts)):\n",
    "    corpus[i] = {\n",
    "        'text': word_tokenize(posts['text'][i]),\n",
    "        'target': posts['target'][i]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def lemmatize(text):\n",
    "    return [morph.parse(word)[0].normal_form for word in text]\n",
    "\n",
    "for i, post in corpus.items():\n",
    "    corpus[i]['text'] = lemmatize(post['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Удаление стоп-слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдем стоп-слова по частоте встречаемости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "word_count = {}\n",
    "total_words = 0\n",
    "for i, post in corpus.items():\n",
    "    for word in post['text']:\n",
    "        word_count[word] = word_count.get(word, 0) + 1\n",
    "        total_words += 1\n",
    "\n",
    "total_words, len(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "min_threshold = 0.00001\n",
    "max_threshold = 0.99999\n",
    "\n",
    "stop_words = []\n",
    "\n",
    "for word, count in word_count.items():\n",
    "    freq = count / total_words\n",
    "    if freq < min_threshold or freq > max_threshold:\n",
    "        stop_words.append(word)\n",
    "\n",
    "stop_words[:20], len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def remove_stop_words(text):\n",
    "    return [word for word in text if word not in stop_words]\n",
    "\n",
    "for i, post in corpus.items():\n",
    "    corpus[i]['text'] = remove_stop_words(post['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохранение предобработанных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "corpus_df = pd.DataFrame(corpus).T\n",
    "corpus_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "corpus_df.to_csv('corpus.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Наивный байесовский классификатор"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разделение данных на обучающую и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = corpus_df['text']\n",
    "y = corpus_df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "concat_train = np.concatenate((X_train.reshape(-1, 1), y_train.reshape(-1, 1)), axis=1)\n",
    "concat_test = np.concatenate((X_test.reshape(-1, 1), y_test.reshape(-1, 1)), axis=1)\n",
    "concat_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение классификатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "class Naive_bayes():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.classes_cnt = {} # class_num: [dataset_class_counter, total_features_in_class_counter]\n",
    "        self.freq = {}        # (feature, class_num): counter\n",
    "        self.unique = set()   # unique features in dataset\n",
    "        self.fitted = False\n",
    "\n",
    "    def fit(self, dataset):\n",
    "        for features, label in dataset:\n",
    "            if label not in self.classes_cnt:\n",
    "                self.classes_cnt[label] = [0, 0]\n",
    "            self.classes_cnt[label][0] += 1\n",
    "            for feature in features:\n",
    "                if (feature, label) not in self.freq:\n",
    "                    self.freq[(feature, label)] = 0\n",
    "                self.freq[(feature, label)] += 1\n",
    "                self.classes_cnt[label][1] += 1\n",
    "                self.unique.add(feature)\n",
    "        self.fitted = True\n",
    "\n",
    "    def predict(self, features, alpha=1):\n",
    "        if not self.fitted: return None\n",
    "        dataset_cnt = 0\n",
    "        for label in self.classes_cnt:\n",
    "            dataset_cnt += self.classes_cnt[label][1]\n",
    "\n",
    "        max_prob = -1\n",
    "        max_label = None\n",
    "        for cls in self.classes_cnt:\n",
    "            cls_prob = self.classes_cnt[cls][0] / dataset_cnt\n",
    "            for feature in features:\n",
    "                if (feature, cls) in self.freq:\n",
    "                    cls_prob += (self.freq[(feature, cls)] + alpha) / (self.classes_cnt[cls][1] + alpha * len(self.unique))\n",
    "                else:\n",
    "                    cls_prob += alpha / (self.classes_cnt[cls][1] + alpha * len(self.unique))\n",
    "            if cls_prob > max_prob:\n",
    "                max_prob = cls_prob\n",
    "                max_label = cls\n",
    "        return max_label\n",
    "\n",
    "    def export_model(self, path='dicts.pkl'):\n",
    "        model = self.classes_cnt, self.freq, self.unique\n",
    "        joblib.dump(model, 'dicts.pkl')\n",
    "        return model\n",
    "\n",
    "    def import_model(self, path='dicts.pkl'):\n",
    "        self.classes_cnt, self.freq, self.unique = joblib.load(path)\n",
    "        self.fitted = True\n",
    "\n",
    "nb = Naive_bayes()\n",
    "nb.fit(concat_train)\n",
    "nb.export_model('dicts.pkl')\n",
    "nb.import_model('dicts.pkl')\n",
    "\n",
    "for k, item in enumerate(concat_test):\n",
    "    print(nb.predict(item[0], alpha=1), ' : ', item[1])\n",
    "    if k == 10: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка качества классификатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for item in concat_test:\n",
    "    y_pred.append(nb.predict(item[0], alpha=1))\n",
    "\n",
    "y_pred = np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# map labels to numbers\n",
    "y_test = np.array([1 if label == 'jumoreski' else 0 for label in y_test])\n",
    "y_pred = np.array([1 if label == 'jumoreski' else 0 for label in y_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "print('Accuracy score:', accuracy_score(y_test, y_pred))\n",
    "print('Precision score:', precision_score(y_test, y_pred))\n",
    "print('Recall score:', recall_score(y_test, y_pred))\n",
    "print('F1-Score score:', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion matrix', fontsize=16)\n",
    "plt.ylabel('True label', fontsize=14)\n",
    "plt.xlabel('Predicted label', fontsize=14)\n",
    "# rename ticks\n",
    "plt.xticks([0.5, 1.5], ['itis', 'jumoreski'], fontsize=14)\n",
    "plt.yticks([0.5, 1.5], ['itis', 'jumoreski'], fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
